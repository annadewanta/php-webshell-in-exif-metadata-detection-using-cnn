{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 01: Persiapan dan Pra-pemrosesan Data\n",
        "\n",
        "Notebook ini mencakup dua proses utama dalam persiapan data untuk penelitian:\n",
        "1.  **Pembuatan Dataset Malicious:** Menyisipkan skrip PHP webshell ke dalam metadata EXIF dari sekumpulan gambar bersih.\n",
        "2.  **Pra-pemrosesan Akhir:** Mengonversi metadata dari seluruh dataset (jinak & berbahaya) menjadi citra *grayscale* dan menyimpannya ke dalam format `.npy` yang efisien untuk pelatihan."
      ],
      "metadata": {
        "id": "U2krLpOnUCdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2g5JeC3T_Eh"
      },
      "outputs": [],
      "source": [
        "# --- Instalasi Pustaka (jika diperlukan) ---\n",
        "# Sebagian besar sudah ada di Colab, tapi ini untuk memastikan\n",
        "!pip install numpy pillow opencv-python pandas tqdm --quiet\n",
        "\n",
        "# --- Hubungkan ke Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Impor Pustaka Utama ---\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import datetime\n",
        "import sys\n",
        "import warnings\n",
        "from PIL import Image, ImageFile\n",
        "from PIL.ExifTags import TAGS\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- Inisialisasi ---\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='PIL')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagian 1: Pembuatan Dataset Malicious\n",
        "\n",
        "Bagian ini akan menginjeksi *payload webshell* ke dalam gambar-gambar bersih untuk menciptakan dataset *malicious*."
      ],
      "metadata": {
        "id": "zmmAEpFAUHG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KONFIGURASI UNTUK INJEKSI ---\n",
        "MAX_EXIF_PAYLOAD_SIZE = 60000\n",
        "\n",
        "# --- FUNGSI-FUNGSI PENDUKUNG UNTUK INJEKSI ---\n",
        "def prepare_webshell_content_for_exif(content_bytes, max_size):\n",
        "    if len(content_bytes) > max_size:\n",
        "        content_bytes = content_bytes[:max_size]\n",
        "    return {'UserComment': content_bytes}\n",
        "\n",
        "def inject_jpeg_metadata(exif_data, webshell_metadata_dict):\n",
        "    tag_map = {v: k for k, v in TAGS.items()}\n",
        "    user_comment_id = tag_map.get('UserComment', 0x9286)\n",
        "    webshell_payload = webshell_metadata_dict.get('UserComment')\n",
        "    if webshell_payload is not None:\n",
        "        exif_data[user_comment_id] = webshell_payload\n",
        "\n",
        "def process_image_with_metadata_injection(input_path, output_path, webshell_content_bytes):\n",
        "    webshell_metadata = prepare_webshell_content_for_exif(webshell_content_bytes, MAX_EXIF_PAYLOAD_SIZE)\n",
        "    if not webshell_metadata.get('UserComment'):\n",
        "        raise ValueError(\"Webshell content is empty after truncation.\")\n",
        "    img = Image.open(input_path)\n",
        "    exif_data = img.getexif()\n",
        "    inject_jpeg_metadata(exif_data, webshell_metadata)\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    img.save(output_path, exif=exif_data, quality=95)\n",
        "    return True\n",
        "\n",
        "def get_webshell_content(ws_path):\n",
        "    with open(ws_path, 'rb') as f:\n",
        "        return f.read()\n",
        "\n",
        "def create_malicious_dataset(input_dir, webshell_dir, output_dir):\n",
        "    print(\"=\"*50)\n",
        "    print(\"MEMULAI PEMBUATAN DATASET MALICIOUS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\">> Mengumpulkan file...\")\n",
        "    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "    webshell_files = [f for f in os.listdir(webshell_dir) if f.endswith('.php')]\n",
        "    if not image_files or not webshell_files:\n",
        "        print(\"!! Error: Pastikan direktori input gambar dan webshell tidak kosong.\")\n",
        "        return\n",
        "\n",
        "    print(f\"-> Ditemukan {len(image_files)} gambar dan {len(webshell_files)} webshell.\")\n",
        "    webshell_sizes = sorted([(f, os.path.getsize(os.path.join(webshell_dir, f))) for f in webshell_files], key=lambda x: x[1])\n",
        "    sorted_webshells = [ws[0] for ws in webshell_sizes]\n",
        "    smallest_webshell_path = os.path.join(webshell_dir, sorted_webshells[0])\n",
        "\n",
        "    random.shuffle(image_files)\n",
        "    success_count = 0\n",
        "\n",
        "    print(\"\\n>> Memulai proses injeksi webshell...\")\n",
        "    for i, img_file in enumerate(tqdm(image_files, desc=\"Injeksi Webshell\", unit=\"file\")):\n",
        "        img_path = os.path.join(input_dir, img_file)\n",
        "        output_file_name = f\"{os.path.splitext(img_file)[0]}_ws_{datetime.datetime.now().strftime('%Y%m%d%H%M%S%f')}.jpg\"\n",
        "        output_path = os.path.join(output_dir, output_file_name)\n",
        "\n",
        "        ws_file_to_try = sorted_webshells[i % len(sorted_webshells)]\n",
        "        ws_path_to_try = os.path.join(webshell_dir, ws_file_to_try)\n",
        "        ws_content_to_try = get_webshell_content(ws_path_to_try)\n",
        "\n",
        "        try:\n",
        "            process_image_with_metadata_injection(img_path, output_path, ws_content_to_try)\n",
        "            success_count += 1\n",
        "        except Exception as e:\n",
        "            if \"EXIF data too long\" in str(e):\n",
        "                try:\n",
        "                    ws_content_smallest = get_webshell_content(smallest_webshell_path)\n",
        "                    process_image_with_metadata_injection(img_path, output_path, ws_content_smallest)\n",
        "                    success_count += 1\n",
        "                except Exception as e_smallest:\n",
        "                    print(f\"ðŸ”´ GAGAL total untuk {img_file}: {e_smallest}\")\n",
        "            else:\n",
        "                print(f\"ðŸ”´ GAGAL total untuk {img_file}: {e}\")\n",
        "\n",
        "    print(f\"\\n--- Ringkasan Proses Injeksi Selesai ---\")\n",
        "    print(f\"Berhasil Diinjeksi: {success_count}/{len(image_files)}\")"
      ],
      "metadata": {
        "id": "N37rNX2KUJwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- JALANKAN PEMBUATAN DATASET MALICIOUS ---\n",
        "\n",
        "input_dir_images = input(\"Masukkan path ke folder gambar bersih (di Drive): \")\n",
        "webshell_dir_scripts = input(\"Masukkan path ke folder skrip webshell (di Drive): \")\n",
        "output_dir_malicious = input(\"Masukkan path folder output untuk gambar malicious (di Drive): \")\n",
        "\n",
        "create_malicious_dataset(input_dir_images, webshell_dir_scripts, output_dir_malicious)"
      ],
      "metadata": {
        "id": "u8cELddoUOSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagian 2: Pra-pemrosesan Menjadi Dataset NumPy\n",
        "\n",
        "Bagian ini akan memproses semua gambar dari folder dataset utama (yang berisi `train`, `val`, `test`), mengonversi metadatanya menjadi citra, dan menyimpannya sebagai file `.npy` yang siap dilatih."
      ],
      "metadata": {
        "id": "VoB78XRzUTQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- KONFIGURASI UNTUK PRA-PEMROSESAN ---\n",
        "IMAGE_SIZE = (256, 256)\n",
        "\n",
        "# --- FUNGSI-FUNGSI PENDUKUNG UNTUK PRA-PEMROSESAN ---\n",
        "def extract_metadata(image_path):\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            exif_data = img.getexif()\n",
        "            return {TAGS.get(tag_id, tag_id): str(value) for tag_id, value in exif_data.items()}\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def metadata_to_image_array(metadata, size=(256, 256)):\n",
        "    try:\n",
        "        byte_array = np.array([], dtype=np.uint8)\n",
        "        if metadata:\n",
        "            metadata_str = json.dumps(metadata, sort_keys=True)\n",
        "            metadata_bytes = metadata_str.encode('utf-8', errors='ignore')\n",
        "            byte_array = np.frombuffer(metadata_bytes, dtype=np.uint8)\n",
        "        max_bytes = size[0] * size[1]\n",
        "        if len(byte_array) > max_bytes:\n",
        "            byte_array = byte_array[:max_bytes]\n",
        "        else:\n",
        "            byte_array = np.pad(byte_array, (0, max_bytes - len(byte_array)), 'constant')\n",
        "        return byte_array.reshape(size)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def create_numpy_dataset(base_path, image_size=(256, 256)):\n",
        "    splits = [\"train\", \"val\", \"test\"]\n",
        "    categories = [\"malicious\", \"benign\"]\n",
        "    numpy_output_path = base_path\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MEMBUAT DATASET NUMPY (.npy)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for split in splits:\n",
        "        images, labels = [], []\n",
        "        print(f\"\\n>> Memproses set data: '{split}'\")\n",
        "        for category in categories:\n",
        "            input_folder = os.path.join(base_path, split, category)\n",
        "            if not os.path.exists(input_folder): continue\n",
        "\n",
        "            image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
        "            for img_file in tqdm(image_files, desc=f\"  -> Kategori '{category}'\", unit=\"file\", leave=False):\n",
        "                img_path = os.path.join(input_folder, img_file)\n",
        "                metadata = extract_metadata(img_path)\n",
        "                img_array = metadata_to_image_array(metadata, size=image_size)\n",
        "\n",
        "                if img_array is not None:\n",
        "                    img_normalized = img_array.astype(np.float32) / 255.0\n",
        "                    img_tensor = np.expand_dims(img_normalized, axis=-1)\n",
        "                    images.append(img_tensor)\n",
        "                    labels.append(1 if category == \"malicious\" else 0)\n",
        "\n",
        "        if images:\n",
        "            np.save(os.path.join(numpy_output_path, f\"X_{split}.npy\"), np.array(images))\n",
        "            np.save(os.path.join(numpy_output_path, f\"y_{split}.npy\"), np.array(labels))\n",
        "            print(f\"âœ… Set '{split}': Berhasil disimpan {len(images)} sampel.\")\n",
        "\n",
        "    print(\"\\nâœ… SEMUA PROSES PERSIAPAN DATA SELESAI\")"
      ],
      "metadata": {
        "id": "BcWR2bFnUPGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- JALANKAN PEMBUATAN DATASET .NPY ---\n",
        "\n",
        "base_path_dataset = input(\"Masukkan path ke folder dataset utama (yang berisi folder train, val, test): \")\n",
        "\n",
        "create_numpy_dataset(base_path_dataset)"
      ],
      "metadata": {
        "id": "UUtLL6YgUWpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}